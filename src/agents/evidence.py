"""
Evidence Builder
SQLçµæœã‚’æ§‹é€ åŒ–ã•ã‚ŒãŸã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã«å¤‰æ›
"""

import json
import re
from dataclasses import dataclass, field
from typing import Any


@dataclass
class Evidence:
    """æ§‹é€ åŒ–ã•ã‚ŒãŸã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹"""

    question: str
    sql: str
    row_count: int

    # ãƒ‡ãƒ¼ã‚¿
    raw_data: list[dict] = field(default_factory=list)

    # é›†è¨ˆå€¤
    # ä¾‹: {"è²»ç”¨": {"åˆè¨ˆ": 200000000, "å¹³å‡": 66000000, ...}}
    aggregations: dict[str, dict[str, float]] = field(default_factory=dict)

    # åˆ†æçµæœ
    # ä¾‹: ["æœ€å¤§ã¯æœ€å°ã®4.3å€", "ã°ã‚‰ã¤ãã¯å¤§ãã„ï¼ˆå¤‰å‹•ä¿‚æ•°53%ï¼‰"]
    analysis: list[str] = field(default_factory=list)

    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    # ä¾‹: [{"rank": 1, "name": "è»¢è·C", "metric": "è²»ç”¨", "value": 92000000}, ...]
    rankings: list[dict] = field(default_factory=list)

    # ã‚«ãƒ†ã‚´ãƒªåˆ†æ
    # ä¾‹: {"best": {"name": "ECã‚µã‚¤ãƒˆ", "avg": 1000}, "worst": {...}}
    category_analysis: dict = field(default_factory=dict)

    # ã‚·ã‚§ã‚¢åˆ†æ
    # ä¾‹: {"top_name": "è»¢è·C", "top_share": 46.1, "top3_share": 100.0}
    share_analysis: dict = field(default_factory=dict)

    def to_prompt(self) -> str:
        """LLMã«æ¸¡ã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå½¢å¼ã«å¤‰æ›"""
        lines = [
            f"## è³ªå•\n{self.question}\n",
            f"## å®Ÿè¡Œã—ãŸSQL\n```sql\n{self.sql}\n```\n",
            f"## ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {self.row_count}ä»¶\n",
        ]

        # é›†è¨ˆå€¤
        if self.aggregations:
            lines.append("### ğŸ“Š é›†è¨ˆå€¤")
            for metric, values in self.aggregations.items():
                for agg_type, value in values.items():
                    lines.append(f"- {metric}ã®{agg_type}: {_format_number(value)}")
            lines.append("")

        # åˆ†æ
        if self.analysis:
            lines.append("### ğŸ“ˆ åˆ†æ")
            for item in self.analysis:
                lines.append(f"- {item}")
            lines.append("")

        # ã‚·ã‚§ã‚¢åˆ†æ
        if self.share_analysis:
            lines.append("### ğŸ“Š ã‚·ã‚§ã‚¢åˆ†æ")
            if "top_name" in self.share_analysis:
                lines.append(
                    f"- ãƒˆãƒƒãƒ—ã®ã€Œ{self.share_analysis['top_name']}ã€ãŒ"
                    f"å…¨ä½“ã®{self.share_analysis['top_share']:.1f}%ã‚’å ã‚ã‚‹"
                )
            if "top3_share" in self.share_analysis:
                lines.append(f"- ä¸Šä½3ä»¶ã§å…¨ä½“ã®{self.share_analysis['top3_share']:.1f}%ã‚’å ã‚ã‚‹")
            lines.append("")

        # ã‚«ãƒ†ã‚´ãƒªåˆ†æ
        if self.category_analysis:
            lines.append("### ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªåˆ†æ")
            if "best" in self.category_analysis:
                best = self.category_analysis["best"]
                lines.append(
                    f"- æœ€ã‚‚åŠ¹ç‡çš„: ã€Œ{best['name']}ã€ç³»ï¼ˆå¹³å‡={_format_number(best['avg'])}ï¼‰"
                )
            if "worst" in self.category_analysis:
                worst = self.category_analysis["worst"]
                ratio = worst.get("ratio", 0)
                lines.append(
                    f"- æ”¹å–„ä½™åœ°ã‚ã‚Š: ã€Œ{worst['name']}ã€ç³»"
                    f"ï¼ˆå¹³å‡={_format_number(worst['avg'])}ã€{ratio:.1f}å€ï¼‰"
                )
            lines.append("")

        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        if self.rankings:
            lines.append("### ğŸ† ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            for r in self.rankings:
                lines.append(
                    f"- ç¬¬{r['rank']}ä½: {r['name']}ï¼ˆ{r['metric']}={_format_number(r['value'])}ï¼‰"
                )
            lines.append("")

        # ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆå…ˆé ­5ä»¶ï¼‰
        if self.raw_data:
            lines.append("### ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ï¼ˆå…ˆé ­5ä»¶ï¼‰")
            for i, row in enumerate(self.raw_data[:5]):
                formatted_row = ", ".join(f"{k}={_format_value(v)}" for k, v in row.items())
                lines.append(f"- {formatted_row}")
            lines.append("")

        return "\n".join(lines)

    def to_dict(self) -> dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
        return {
            "question": self.question,
            "sql": self.sql,
            "row_count": self.row_count,
            "aggregations": self.aggregations,
            "analysis": self.analysis,
            "rankings": self.rankings,
            "share_analysis": self.share_analysis,
            "category_analysis": self.category_analysis,
        }


# ================== ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ==================


def _format_number(value: float) -> str:
    """æ•°å€¤ã‚’èª­ã¿ã‚„ã™ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if value is None:
        return "N/A"
    try:
        value = float(value)
        if abs(value) >= 1_000_000:
            return f"{value/1_000_000:,.2f}M"
        elif abs(value) >= 1_000:
            return f"{value/1_000:,.2f}K"
        elif abs(value) < 1 and value != 0:
            return f"{value:.4f}"
        return f"{value:,.2f}"
    except (ValueError, TypeError):
        return str(value)


def _format_value(value: Any) -> str:
    """å€¤ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆæ•°å€¤ä»¥å¤–ã‚‚å¯¾å¿œï¼‰"""
    if value is None:
        return "N/A"
    try:
        num = float(value)
        return _format_number(num)
    except (ValueError, TypeError):
        return str(value)


def _parse_sql_result(sql_result: str) -> list[dict]:
    """SQLçµæœã‚’ãƒ‘ãƒ¼ã‚¹"""
    try:
        match = re.search(r"\[.*\]", sql_result, re.DOTALL)
        if match:
            return json.loads(match.group())
    except json.JSONDecodeError:
        pass
    return []


def _get_label(col: str) -> str:
    """ã‚«ãƒ©ãƒ åã‹ã‚‰æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã‚’å–å¾—"""
    col_lower = col.lower()

    # åŸºæœ¬æŒ‡æ¨™
    labels = {
        "impressions": "è¡¨ç¤ºå›æ•°",
        "clicks": "ã‚¯ãƒªãƒƒã‚¯æ•°",
        "cost": "è²»ç”¨",
        "conversions": "CVæ•°",
        "conversion_value": "CVä¾¡å€¤",
        "ctr": "CTR",
        "cpc": "CPC",
        "cvr": "CVR",
        "cpa": "CPA",
        "roas": "ROAS",
    }

    if col_lower in labels:
        return labels[col_lower]

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
    patterns = {
        "impression": "è¡¨ç¤ºå›æ•°",
        "click": "ã‚¯ãƒªãƒƒã‚¯æ•°",
        "cost": "è²»ç”¨",
        "conversion": "CVæ•°",
        "spend": "è²»ç”¨",
        "cpa": "CPA",
        "cpc": "CPC",
        "ctr": "CTR",
        "cvr": "CVR",
        "roas": "ROAS",
    }

    prefixes = {
        "total": "ç·",
        "sum": "åˆè¨ˆ",
        "avg": "å¹³å‡",
        "average": "å¹³å‡",
        "max": "æœ€å¤§",
        "min": "æœ€å°",
    }

    # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹æ¤œå‡º
    prefix_label = ""
    remaining = col_lower
    for prefix, jp_prefix in prefixes.items():
        if remaining.startswith(prefix + "_"):
            prefix_label = jp_prefix
            remaining = remaining[len(prefix) + 1 :]
            break

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
    for pattern, label in sorted(patterns.items(), key=lambda x: -len(x[0])):
        if pattern in remaining:
            return f"{prefix_label}{label}" if prefix_label else label

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if prefix_label:
        return f"{prefix_label}{remaining.replace('_', ' ').title()}"
    return col.replace("_", " ").title()


def _detect_columns(row: dict) -> tuple[str | None, list[str]]:
    """ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³åˆ—ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ—ã‚’æ¤œå‡º"""
    dimension = None
    metrics = []

    for col, val in row.items():
        col_lower = col.lower()

        # IDã‚«ãƒ©ãƒ ã¯é™¤å¤–
        if col_lower.endswith("_id") or col_lower == "id":
            continue

        # nameã‚’å«ã‚€ã‚«ãƒ©ãƒ ã¯ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³
        if "name" in col_lower:
            dimension = col
            continue

        # æ•°å€¤å‹ã¯ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        if val is not None:
            try:
                float(val)
                metrics.append(col)
            except (ValueError, TypeError):
                # æ–‡å­—åˆ—å‹ã§ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãŒæœªè¨­å®šãªã‚‰è¨­å®š
                if dimension is None:
                    dimension = col

    # é‡è¦ãªæŒ‡æ¨™ã‚’å…ˆã«ã‚½ãƒ¼ãƒˆ
    priority = ["cpa", "roas", "cpc", "cvr", "ctr", "cost", "conversions", "clicks", "impressions"]

    def metric_priority(col: str) -> int:
        col_lower = col.lower()
        for i, p in enumerate(priority):
            if p in col_lower:
                return i
        return 100

    metrics = sorted(metrics, key=metric_priority)

    return dimension, metrics


def _calculate_aggregations(
    data: list[dict], metric_cols: list[str]
) -> dict[str, dict[str, float]]:
    """é›†è¨ˆå€¤ã‚’è¨ˆç®—"""
    result = {}

    for col in metric_cols[:5]:  # ä¸Šä½5æŒ‡æ¨™
        values = []
        for row in data:
            if col in row and row[col] is not None:
                try:
                    values.append(float(row[col]))
                except (ValueError, TypeError):
                    pass

        if values:
            label = _get_label(col)
            result[label] = {
                "åˆè¨ˆ": sum(values),
                "å¹³å‡": sum(values) / len(values),
                "æœ€å¤§": max(values),
                "æœ€å°": min(values),
            }

    return result


def _generate_analysis(data: list[dict], metric_cols: list[str]) -> list[str]:
    """åˆ†æã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ"""
    analysis = []

    for col in metric_cols[:3]:  # ä¸Šä½3æŒ‡æ¨™
        values = []
        for row in data:
            if col in row and row[col] is not None:
                try:
                    values.append(float(row[col]))
                except (ValueError, TypeError):
                    pass

        if not values:
            continue

        label = _get_label(col)
        max_val = max(values)
        min_val = min(values)
        avg_val = sum(values) / len(values)

        # æ¯”ç‡åˆ†æ
        if min_val > 0:
            ratio = max_val / min_val
            analysis.append(f"{label}ã®æœ€å¤§ã¯æœ€å°ã®{ratio:.1f}å€")

        # ã°ã‚‰ã¤ãåˆ†æï¼ˆå¤‰å‹•ä¿‚æ•°ï¼‰
        if len(values) >= 2 and avg_val > 0:
            variance = sum((v - avg_val) ** 2 for v in values) / len(values)
            std_dev = variance**0.5
            cv = (std_dev / avg_val) * 100

            if cv > 50:
                dispersion = "éå¸¸ã«å¤§ãã„"
            elif cv > 30:
                dispersion = "å¤§ãã„"
            elif cv > 15:
                dispersion = "ä¸­ç¨‹åº¦"
            else:
                dispersion = "å°ã•ã„"

            analysis.append(f"{label}ã®ã°ã‚‰ã¤ãã¯{dispersion}ï¼ˆå¤‰å‹•ä¿‚æ•°{cv:.1f}%ï¼‰")

    return analysis


def _generate_rankings(data: list[dict], dimension: str | None, metric: str) -> list[dict]:
    """ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ç”Ÿæˆ"""
    if not dimension:
        return []

    valid_data = []
    for row in data:
        if metric in row and row[metric] is not None:
            try:
                valid_data.append({"name": row.get(dimension, "ä¸æ˜"), "value": float(row[metric])})
            except (ValueError, TypeError):
                pass

    sorted_data = sorted(valid_data, key=lambda x: x["value"], reverse=True)
    metric_label = _get_label(metric)

    return [
        {"rank": i + 1, "name": d["name"], "metric": metric_label, "value": d["value"]}
        for i, d in enumerate(sorted_data[:5])
    ]


def _calculate_share_analysis(data: list[dict], dimension: str | None, metric: str) -> dict:
    """ã‚·ã‚§ã‚¢åˆ†æã‚’è¨ˆç®—"""
    if not dimension:
        return {}

    values_with_names = []
    for row in data:
        if metric in row and row[metric] is not None:
            try:
                val = float(row[metric])
                name = row.get(dimension, "ä¸æ˜")
                values_with_names.append((name, val))
            except (ValueError, TypeError):
                pass

    if not values_with_names:
        return {}

    total = sum(v for _, v in values_with_names)
    if total <= 0:
        return {}

    sorted_values = sorted(values_with_names, key=lambda x: x[1], reverse=True)
    top_name, top_value = sorted_values[0]
    top_share = (top_value / total) * 100

    result = {"top_name": top_name, "top_share": top_share}

    if len(sorted_values) >= 3:
        top3_total = sum(v for _, v in sorted_values[:3])
        result["top3_share"] = (top3_total / total) * 100

    return result


def _calculate_category_analysis(data: list[dict], dimension: str | None, metric: str) -> dict:
    """ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æã‚’è¨ˆç®—"""
    if not dimension:
        return {}

    # åå‰ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’æŠ½å‡º
    category_values: dict[str, list[float]] = {}
    for row in data:
        if metric in row and row[metric] is not None:
            try:
                val = float(row[metric])
                name = str(row.get(dimension, ""))
                category = name.split("_")[0] if "_" in name else name
                if category:
                    if category not in category_values:
                        category_values[category] = []
                    category_values[category].append(val)
            except (ValueError, TypeError):
                pass

    if len(category_values) < 2:
        return {}

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å¹³å‡ã‚’è¨ˆç®—
    category_avgs = [
        (cat, sum(vals) / len(vals), len(vals)) for cat, vals in category_values.items()
    ]
    category_avgs.sort(key=lambda x: x[1])

    best_cat, best_avg, _ = category_avgs[0]
    worst_cat, worst_avg, _ = category_avgs[-1]

    # CPAãªã©ã¯ä½ã„æ–¹ãŒè‰¯ã„
    metric_lower = metric.lower()
    if any(x in metric_lower for x in ["cpa", "cpc", "cost"]):
        return {
            "best": {"name": best_cat, "avg": best_avg},
            "worst": {
                "name": worst_cat,
                "avg": worst_avg,
                "ratio": worst_avg / best_avg if best_avg > 0 else 0,
            },
        }
    else:
        # CVæ•°ãªã©ã¯é«˜ã„æ–¹ãŒè‰¯ã„
        return {
            "best": {"name": worst_cat, "avg": worst_avg},
            "worst": {
                "name": best_cat,
                "avg": best_avg,
                "ratio": worst_avg / best_avg if best_avg > 0 else 0,
            },
        }


# ================== ãƒ¡ã‚¤ãƒ³é–¢æ•° ==================


def build_evidence(sql_result: str, sql_query: str, question: str) -> Evidence:
    """
    SQLçµæœã‹ã‚‰Evidenceã‚’æ§‹ç¯‰

    Args:
        sql_result: SQLå®Ÿè¡Œçµæœï¼ˆJSONæ–‡å­—åˆ—ï¼‰
        sql_query: å®Ÿè¡Œã—ãŸSQL
        question: å…ƒã®è³ªå•

    Returns:
        Evidence: æ§‹é€ åŒ–ã•ã‚ŒãŸã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹
    """
    data = _parse_sql_result(sql_result)

    if not data:
        return Evidence(question=question, sql=sql_query, row_count=0)

    dimension, metrics = _detect_columns(data[0])

    # å„ç¨®åˆ†æã‚’å®Ÿè¡Œ
    aggregations = {}
    analysis = []
    rankings = []
    share_analysis = {}
    category_analysis = {}

    if len(data) >= 1 and metrics:
        aggregations = _calculate_aggregations(data, metrics)

    if len(data) >= 2 and metrics:
        analysis = _generate_analysis(data, metrics)
        share_analysis = _calculate_share_analysis(data, dimension, metrics[0])
        category_analysis = _calculate_category_analysis(data, dimension, metrics[0])

    if dimension and metrics:
        rankings = _generate_rankings(data, dimension, metrics[0])

    return Evidence(
        question=question,
        sql=sql_query,
        row_count=len(data),
        raw_data=data,
        aggregations=aggregations,
        analysis=analysis,
        rankings=rankings,
        share_analysis=share_analysis,
        category_analysis=category_analysis,
    )
